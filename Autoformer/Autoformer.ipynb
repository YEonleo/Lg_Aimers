{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7444f30-0883-4a87-8e00-c5e5591a2a26",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b85832b1-9f31-41e4-b934-cc260e5b3b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b0259cfd-b37c-4716-aacf-c91d77e41480",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "device = torch.device('cuda:1') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c2d47b-e9da-47e5-9155-cce997e63481",
   "metadata": {},
   "source": [
    "## Hyperparameter Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c9f50013-6513-44fd-8e48-06dd12ec3f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'TRAIN_WINDOW_SIZE':90, # 90일치로 학습 pred_len\n",
    "    'PREDICT_SIZE':21, # 21일치 예측 label_len\n",
    "    'freq':'d',# seasonal, trend 정보를 어떤걸 기준으로 할지\n",
    "    'enc_in':1,#encoder input size\n",
    "    'dec_in':1,#decoder input size\n",
    "    'embed':'fixed',#time features encoding, options:[timeF, fixed, learned]\n",
    "    'drop_out':0.1,\n",
    "    'EPOCHS':10,\n",
    "    'LEARNING_RATE':1e-4,\n",
    "    'BATCH_SIZE':512,\n",
    "    'd_model':512,\n",
    "    'd_ff':2048,\n",
    "    'e_layers':2,\n",
    "    'd_layers':1,\n",
    "    'n_heads': 8,\n",
    "    'factor': 1,\n",
    "    'c_out': 1,\n",
    "    'SEED':41,\n",
    "    'output_attention':'store_true'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "77bf8664",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scaler(train_data):\n",
    "    scale_max_dict = {}\n",
    "    scale_min_dict = {}\n",
    "\n",
    "    numeric_cols = train_data.columns[2:]\n",
    "\n",
    "    # 각 행의 최댓값과 최솟값 계산\n",
    "    min_values = train_data[numeric_cols].min(axis=1)\n",
    "    max_values = train_data[numeric_cols].max(axis=1)\n",
    "    print(max(max_values))\n",
    "\n",
    "    # 각 행의 범위(max - min) 계산하고, 범위가 0인 경우 1로 대체\n",
    "    ranges = max_values - min_values\n",
    "    ranges[ranges == 0] = 1\n",
    "\n",
    "    # min-max scaling 수행\n",
    "    train_data[numeric_cols] = (train_data[numeric_cols].subtract(min_values, axis=0)).div(ranges, axis=0)\n",
    "\n",
    "    # max와 min 값을 dictionary 형태로 저장\n",
    "    scale_min_dict = min_values.to_dict()\n",
    "    scale_max_dict = max_values.to_dict()\n",
    "\n",
    "    # Label Encoding\n",
    "    label_encoder = LabelEncoder()\n",
    "    categorical_columns = ['대분류', '중분류']#, '대분류',]\n",
    "\n",
    "    for col in categorical_columns:\n",
    "        label_encoder.fit(train_data[col])\n",
    "        train_data[col] = label_encoder.transform(train_data[col])\n",
    "\n",
    "    return train_data, scale_max_dict, scale_min_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d68c38e",
   "metadata": {},
   "source": [
    "### 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e3b89389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "# 경고 메시지 무시\n",
    "warnings.filterwarnings('ignore', category=pd.errors.PerformanceWarning)\n",
    "\n",
    "\n",
    "# 데이터를 읽어옵니다.\n",
    "train_df = pd.read_csv('./data/train.csv').drop(columns=['ID', '제품', '소분류', '브랜드']).head(10)\n",
    "train_df, scale_max_dict, scale_min_dict = min_max_scaler(train_df)\n",
    "\n",
    "date_columns = [col for col in train_df.columns if '-' in col]\n",
    "date_info = pd.DataFrame(date_columns, columns=[\"full_date\"])\n",
    "\n",
    "# 연, 월, 일로 분리\n",
    "date_info[\"year\"] = date_info[\"full_date\"].apply(lambda x: int(x.split(\"-\")[0]))\n",
    "date_info[\"month\"] = date_info[\"full_date\"].apply(lambda x: int(x.split(\"-\")[1]))\n",
    "date_info[\"day\"] = date_info[\"full_date\"].apply(lambda x: int(x.split(\"-\")[2]))\n",
    "\n",
    "new_columns = []\n",
    "\n",
    "# 연, 월, 일 정보를 저장할 새로운 DataFrame을 생성합니다.\n",
    "for idx, col in enumerate(date_columns):\n",
    "    year_col = col + \"_year\"\n",
    "    month_col = col + \"_month\"\n",
    "    day_col = col + \"_day\"\n",
    "    \n",
    "    train_df[year_col] = [date_info.iloc[idx][\"year\"]] * len(train_df)\n",
    "    train_df[month_col] = [date_info.iloc[idx][\"month\"]] * len(train_df)\n",
    "    train_df[day_col] = [date_info.iloc[idx][\"day\"]] * len(train_df)\n",
    "    \n",
    "    new_columns.extend([year_col, month_col, day_col])\n",
    "\n",
    "# 경고를 방지하기 위해 DataFrame을 복사합니다.\n",
    "train_df = train_df.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21e80a6",
   "metadata": {},
   "source": [
    "### 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9ce47176",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "def process_row(i, data, sales_cols, train_size, predict_size, window_size, encode_info):\n",
    "    num_rows = len(data)\n",
    "    input_data_row = np.empty((len(sales_cols) - window_size + 1, train_size, 6))\n",
    "    target_data_row = np.empty((len(sales_cols) - window_size + 1, predict_size, 4))\n",
    "    \n",
    "    for j in range(len(sales_cols) - window_size + 1):\n",
    "        sales_window = data[sales_cols[j: j + train_size]].iloc[i].values\n",
    "        year_window = (data[[col + \"_year\" for col in sales_cols[j: j + train_size]]].iloc[i].values - 2022)\n",
    "        month_window = data[[col + \"_month\" for col in sales_cols[j: j + train_size]]].iloc[i].values\n",
    "        day_window = data[[col + \"_day\" for col in sales_cols[j: j + train_size]]].iloc[i].values\n",
    "        \n",
    "        combined_window = np.column_stack((np.tile(encode_info, (train_size, 1)), sales_window, year_window, month_window, day_window))\n",
    "        input_data_row[j] = combined_window\n",
    "\n",
    "        target_year = (data[[col + \"_year\" for col in sales_cols[j + train_size: j + window_size]]].iloc[i].values - 2022)\n",
    "        target_month = data[[col + \"_month\" for col in sales_cols[j + train_size: j + window_size]]].iloc[i].values\n",
    "        target_day = data[[col + \"_day\" for col in sales_cols[j + train_size: j + window_size]]].iloc[i].values\n",
    "        target_sales = data[sales_cols[j + train_size: j + window_size]].iloc[i].values\n",
    "\n",
    "        combined_target = np.column_stack((target_sales, target_year, target_month, target_day))\n",
    "        target_data_row[j] = combined_target\n",
    "\n",
    "    return input_data_row, target_data_row\n",
    "\n",
    "def make_train_data_parallel(data, train_size, predict_size):\n",
    "    num_rows = len(data)\n",
    "    window_size = train_size + predict_size\n",
    "    \n",
    "    sales_cols = [col for col in data.columns if '-' in col and not any(substr in col for substr in ['_year', '_month', '_day'])]\n",
    "    \n",
    "    input_data = np.empty((num_rows * (len(sales_cols) - window_size + 1), train_size, 6))\n",
    "    target_data = np.empty((num_rows * (len(sales_cols) - window_size + 1), predict_size, 4))\n",
    "    \n",
    "    results = Parallel(n_jobs=-1)(delayed(process_row)(i, data, sales_cols, train_size, predict_size, window_size, data.iloc[i, :2].values) for i in range(num_rows))\n",
    "    \n",
    "    for i, (input_data_row, target_data_row) in enumerate(results):\n",
    "        input_data[i * (len(sales_cols) - window_size + 1): (i + 1) * (len(sales_cols) - window_size + 1)] = input_data_row\n",
    "        target_data[i * (len(sales_cols) - window_size + 1): (i + 1) * (len(sales_cols) - window_size + 1)] = target_data_row\n",
    "\n",
    "    return input_data, target_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7c83c51b-f979-4930-9372-f03bdb33abc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input, train_target = make_train_data_parallel(train_df, CFG['TRAIN_WINDOW_SIZE'], CFG['PREDICT_SIZE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3c710abd-1be0-4926-803f-c732d7bffdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train / Validation Split\n",
    "data_len = len(train_input)\n",
    "val_input = train_input[-int(data_len*0.2):]\n",
    "val_target = train_target[-int(data_len*0.2):]\n",
    "train_input = train_input[:-int(data_len*0.2)]\n",
    "train_target = train_target[:-int(data_len*0.2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2f3d76-fcf4-4866-a578-6bb76783bbed",
   "metadata": {},
   "source": [
    "### Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4ec0a970-4d99-486d-b9b5-210f3cdca353",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = torch.Tensor(X)\n",
    "        self.Y = torch.Tensor(Y)\n",
    "        self.sales_feature_size = 3  # 대분류, 중분류, 판매량\n",
    "        self.time_feature_size = 3  # 연, 월, 일\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "    # 판매량 추출\n",
    "        sales_data = self.X[index, :, 2:3]  # 판매량은 3번째 칼럼에 위치한다고 가정\n",
    "        # 대분류, 중분류 정보 추출\n",
    "        product_data = self.X[index, :, :2]  # 대분류와 중분류는 처음 두 칼럼에 위치한다고 가정\n",
    "        \n",
    "        # 연, 월, 일 정보 추출\n",
    "        input_time_features = self.X[index, :, self.sales_feature_size:]\n",
    "        \n",
    "        # target_data에서 판매량 및 연, 월, 일 정보 추출\n",
    "        target_sales = self.Y[index, :, 0]\n",
    "        target_time_features = self.Y[index, :, 1:]\n",
    "        \n",
    "        return product_data.long(), sales_data, target_sales, input_time_features, target_time_features\n",
    "\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3614347b-da14-466f-9d04-b81e5448a9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_input, train_target)\n",
    "train_loader = DataLoader(train_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=True)\n",
    "\n",
    "val_dataset = CustomDataset(val_input, val_target)\n",
    "val_loader = DataLoader(val_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f79f7d",
   "metadata": {},
   "source": [
    "### 모델 학습"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "84dc3c2a",
   "metadata": {},
   "source": [
    "## Autoformer Embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9cf7609a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compared_version(ver1, ver2):\n",
    "    \"\"\"\n",
    "    :param ver1\n",
    "    :param ver2\n",
    "    :return: ver1< = >ver2 False/True\n",
    "    \"\"\"\n",
    "    list1 = str(ver1).split(\".\")\n",
    "    list2 = str(ver2).split(\".\")\n",
    "    \n",
    "    for i in range(len(list1)) if len(list1) < len(list2) else range(len(list2)):\n",
    "        if int(list1[i]) == int(list2[i]):\n",
    "            pass\n",
    "        elif int(list1[i]) < int(list2[i]):\n",
    "            return -1\n",
    "        else:\n",
    "            return 1\n",
    "    \n",
    "    if len(list1) == len(list2):\n",
    "        return True\n",
    "    elif len(list1) < len(list2):\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "46fee215",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeFeatureEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, embed_type='timeF', freq='d'):\n",
    "        super(TimeFeatureEmbedding, self).__init__()\n",
    "\n",
    "        freq_map = {'h': 4, 't': 5, 's': 6, 'm': 1, 'a': 1, 'w': 2, 'd': 3, 'b': 3}\n",
    "        d_inp = freq_map[freq]\n",
    "        self.embed = nn.Linear(d_inp, d_model, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embed(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5252ddcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FixedEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model):\n",
    "        super(FixedEmbedding, self).__init__()\n",
    "\n",
    "        w = torch.zeros(c_in, d_model).float()\n",
    "        w.require_grad = False\n",
    "\n",
    "        position = torch.arange(0, c_in).float().unsqueeze(1)\n",
    "        div_term = (torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model)).exp()\n",
    "\n",
    "        w[:, 0::2] = torch.sin(position * div_term)\n",
    "        w[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        self.emb = nn.Embedding(c_in, d_model)\n",
    "        self.emb.weight = nn.Parameter(w, requires_grad=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.emb(x).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3b3b7b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataEmbedding_wo_pos(nn.Module):\n",
    "    def __init__(self, c_in, d_model, major_size,minor_size, embed_type='fixed', freq='d', dropout=0.1):#대분류,중분류 사이즈별 임베딩\n",
    "        super(DataEmbedding_wo_pos, self).__init__()\n",
    "        self.major_embedding = nn.Embedding(major_size, d_model)\n",
    "        self.minor_embedding = nn.Embedding(minor_size, d_model)\n",
    "\n",
    "        \n",
    "        self.value_embedding = TokenEmbedding(c_in=c_in, d_model=d_model)\n",
    "        self.position_embedding = PositionalEmbedding(d_model=d_model)\n",
    "        self.temporal_embedding = TemporalEmbedding(d_model=d_model, embed_type=embed_type, freq=freq)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, product_data, x, x_mark):\n",
    "        x_embed = self.value_embedding(x)\n",
    "        \n",
    "        major_info = product_data[:, :, 0] # 대분류\n",
    "        minor_info = product_data[:, :, 1] # 중분류\n",
    "        \n",
    "        major_embed = self.major_embedding(major_info)\n",
    "        minor_embed = self.minor_embedding(minor_info)\n",
    "        \n",
    "        product_embed = major_embed + minor_embed\n",
    "        \n",
    "        x = x_embed + product_embed + self.temporal_embedding(x_mark)\n",
    "        \n",
    "        return self.dropout(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c3211e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        padding = 1 if compared_version(torch.__version__, '1.5.0') else 2\n",
    "        self.tokenConv = nn.Conv1d(in_channels=c_in, out_channels=d_model,\n",
    "                                   kernel_size=3, padding=padding, padding_mode='circular', bias=False)\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='leaky_relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.tokenConv(x.permute(0, 2, 1)).transpose(1, 2)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fbe96773",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, embed_type='fixed', freq='d'):  # freq를 'd'로 변경\n",
    "        super(TemporalEmbedding, self).__init__()\n",
    "\n",
    "        year_size = 2  # 예시로 임의의 년도 크기 사용 (2022, 2023)\n",
    "        month_size = 13\n",
    "        day_size = 32\n",
    "\n",
    "        Embed = FixedEmbedding if embed_type == 'fixed' else nn.Embedding\n",
    "        if freq == 'd':\n",
    "            self.year_embed = Embed(year_size, d_model)\n",
    "            self.month_embed = Embed(month_size, d_model)\n",
    "            self.day_embed = Embed(day_size, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.long()\n",
    "\n",
    "        year_x = self.year_embed(x[:, :, 0])\n",
    "        month_x = self.month_embed(x[:, :, 1])\n",
    "        day_x = self.day_embed(x[:, :, 2])\n",
    "\n",
    "        return year_x + month_x + day_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d3dc193c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model).float()\n",
    "        pe.require_grad = False\n",
    "\n",
    "        position = torch.arange(0, max_len).float().unsqueeze(1)\n",
    "        div_term = (torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model)).exp()\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pe[:, :x.size(1)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b6b3418c",
   "metadata": {},
   "source": [
    "## AutoCorellation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a8867b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoCorrelation(nn.Module):\n",
    "    \"\"\"\n",
    "    AutoCorrelation Mechanism with the following two phases:\n",
    "    (1) period-based dependencies discovery\n",
    "    (2) time delay aggregation\n",
    "    This block can replace the self-attention family mechanism seamlessly.\n",
    "    \"\"\"\n",
    "    def __init__(self, mask_flag=True, factor=1, scale=None, attention_dropout=0.1, output_attention=False):\n",
    "        super(AutoCorrelation, self).__init__()\n",
    "        self.factor = factor\n",
    "        self.scale = scale\n",
    "        self.mask_flag = mask_flag\n",
    "        self.output_attention = output_attention\n",
    "        self.dropout = nn.Dropout(attention_dropout)\n",
    "\n",
    "    def time_delay_agg_training(self, values, corr):\n",
    "        \"\"\"\n",
    "        SpeedUp version of Autocorrelation (a batch-normalization style design)\n",
    "        This is for the training phase.\n",
    "        \"\"\"\n",
    "        head = values.shape[1]\n",
    "        channel = values.shape[2]\n",
    "        length = values.shape[3]\n",
    "        # find top k\n",
    "        top_k = int(self.factor * math.log(length))\n",
    "        mean_value = torch.mean(torch.mean(corr, dim=1), dim=1)\n",
    "        index = torch.topk(torch.mean(mean_value, dim=0), top_k, dim=-1)[1]\n",
    "        weights = torch.stack([mean_value[:, index[i]] for i in range(top_k)], dim=-1)\n",
    "        # update corr\n",
    "        tmp_corr = torch.softmax(weights, dim=-1)\n",
    "        # aggregation\n",
    "        tmp_values = values\n",
    "        delays_agg = torch.zeros_like(values).float()\n",
    "        for i in range(top_k):\n",
    "            pattern = torch.roll(tmp_values, -int(index[i]), -1)\n",
    "            delays_agg = delays_agg + pattern * \\\n",
    "                         (tmp_corr[:, i].unsqueeze(1).unsqueeze(1).unsqueeze(1).repeat(1, head, channel, length))\n",
    "        return delays_agg\n",
    "\n",
    "    def time_delay_agg_inference(self, values, corr):\n",
    "        \"\"\"\n",
    "        SpeedUp version of Autocorrelation (a batch-normalization style design)\n",
    "        This is for the inference phase.\n",
    "        \"\"\"\n",
    "        batch = values.shape[0]\n",
    "        head = values.shape[1]\n",
    "        channel = values.shape[2]\n",
    "        length = values.shape[3]\n",
    "        # index init\n",
    "        init_index = torch.arange(length).unsqueeze(0).unsqueeze(0).unsqueeze(0)\\\n",
    "            .repeat(batch, head, channel, 1).to(values.device)\n",
    "        # find top k\n",
    "        top_k = int(self.factor * math.log(length))\n",
    "        mean_value = torch.mean(torch.mean(corr, dim=1), dim=1)\n",
    "        weights, delay = torch.topk(mean_value, top_k, dim=-1)\n",
    "        # update corr\n",
    "        tmp_corr = torch.softmax(weights, dim=-1)\n",
    "        # aggregation\n",
    "        tmp_values = values.repeat(1, 1, 1, 2)\n",
    "        delays_agg = torch.zeros_like(values).float()\n",
    "        for i in range(top_k):\n",
    "            tmp_delay = init_index + delay[:, i].unsqueeze(1).unsqueeze(1).unsqueeze(1).repeat(1, head, channel, length)\n",
    "            pattern = torch.gather(tmp_values, dim=-1, index=tmp_delay)\n",
    "            delays_agg = delays_agg + pattern * \\\n",
    "                         (tmp_corr[:, i].unsqueeze(1).unsqueeze(1).unsqueeze(1).repeat(1, head, channel, length))\n",
    "        return delays_agg\n",
    "\n",
    "    def time_delay_agg_full(self, values, corr):\n",
    "        \"\"\"\n",
    "        Standard version of Autocorrelation\n",
    "        \"\"\"\n",
    "        batch = values.shape[0]\n",
    "        head = values.shape[1]\n",
    "        channel = values.shape[2]\n",
    "        length = values.shape[3]\n",
    "        # index init\n",
    "        init_index = torch.arange(length).unsqueeze(0).unsqueeze(0).unsqueeze(0)\\\n",
    "            .repeat(batch, head, channel, 1).to(values.device)\n",
    "        # find top k\n",
    "        top_k = int(self.factor * math.log(length))\n",
    "        weights, delay = torch.topk(corr, top_k, dim=-1)\n",
    "        # update corr\n",
    "        tmp_corr = torch.softmax(weights, dim=-1)\n",
    "        # aggregation\n",
    "        tmp_values = values.repeat(1, 1, 1, 2)\n",
    "        delays_agg = torch.zeros_like(values).float()\n",
    "        for i in range(top_k):\n",
    "            tmp_delay = init_index + delay[..., i].unsqueeze(-1)\n",
    "            pattern = torch.gather(tmp_values, dim=-1, index=tmp_delay)\n",
    "            delays_agg = delays_agg + pattern * (tmp_corr[..., i].unsqueeze(-1))\n",
    "        return delays_agg\n",
    "\n",
    "    def forward(self, queries, keys, values, attn_mask):\n",
    "        B, L, H, E = queries.shape\n",
    "        _, S, _, D = values.shape\n",
    "        if L > S:\n",
    "            zeros = torch.zeros_like(queries[:, :(L - S), :]).float()\n",
    "            values = torch.cat([values, zeros], dim=1)\n",
    "            keys = torch.cat([keys, zeros], dim=1)\n",
    "        else:\n",
    "            values = values[:, :L, :, :]\n",
    "            keys = keys[:, :L, :, :]\n",
    "\n",
    "        # period-based dependencies\n",
    "        q_fft = torch.fft.rfft(queries.permute(0, 2, 3, 1).contiguous(), dim=-1)\n",
    "        k_fft = torch.fft.rfft(keys.permute(0, 2, 3, 1).contiguous(), dim=-1)\n",
    "        res = q_fft * torch.conj(k_fft)\n",
    "        corr = torch.fft.irfft(res, n=L, dim=-1)\n",
    "\n",
    "        # time delay agg\n",
    "        if self.training:\n",
    "            V = self.time_delay_agg_training(values.permute(0, 2, 3, 1).contiguous(), corr).permute(0, 3, 1, 2)\n",
    "        else:\n",
    "            V = self.time_delay_agg_inference(values.permute(0, 2, 3, 1).contiguous(), corr).permute(0, 3, 1, 2)\n",
    "\n",
    "        if self.output_attention:\n",
    "            return (V.contiguous(), corr.permute(0, 3, 1, 2))\n",
    "        else:\n",
    "            return (V.contiguous(), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "96f7e3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoCorrelationLayer(nn.Module):\n",
    "    def __init__(self, correlation, d_model, n_heads, d_keys=None,\n",
    "                 d_values=None):\n",
    "        super(AutoCorrelationLayer, self).__init__()\n",
    "\n",
    "        d_keys = d_keys or (d_model // n_heads)\n",
    "        d_values = d_values or (d_model // n_heads)\n",
    "\n",
    "        self.inner_correlation = correlation\n",
    "        self.query_projection = nn.Linear(d_model, d_keys * n_heads)\n",
    "        self.key_projection = nn.Linear(d_model, d_keys * n_heads)\n",
    "        self.value_projection = nn.Linear(d_model, d_values * n_heads)\n",
    "        self.out_projection = nn.Linear(d_values * n_heads, d_model)\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "    def forward(self, queries, keys, values, attn_mask):\n",
    "        B, L, _ = queries.shape\n",
    "        _, S, _ = keys.shape\n",
    "        H = self.n_heads\n",
    "\n",
    "        queries = self.query_projection(queries).view(B, L, H, -1)\n",
    "        keys = self.key_projection(keys).view(B, S, H, -1)\n",
    "        values = self.value_projection(values).view(B, S, H, -1)\n",
    "\n",
    "        out, attn = self.inner_correlation(\n",
    "            queries,\n",
    "            keys,\n",
    "            values,\n",
    "            attn_mask\n",
    "        )\n",
    "        out = out.view(B, L, -1)\n",
    "\n",
    "        return self.out_projection(out), attn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bb9d700c",
   "metadata": {},
   "source": [
    "## Autoformer Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b98bcb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_Layernorm(nn.Module):\n",
    "    \"\"\"\n",
    "    Special designed layernorm for the seasonal part\n",
    "    \"\"\"\n",
    "    def __init__(self, channels):\n",
    "        super(my_Layernorm, self).__init__()\n",
    "        self.layernorm = nn.LayerNorm(channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_hat = self.layernorm(x)\n",
    "        bias = torch.mean(x_hat, dim=1).unsqueeze(1).repeat(1, x.shape[1], 1)\n",
    "        return x_hat - bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "797a6b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Autoformer encoder layer with the progressive decomposition architecture\n",
    "    \"\"\"\n",
    "    def __init__(self, attention, d_model, d_ff=None, moving_avg=25, dropout=0.1, activation=\"relu\"):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        d_ff = d_ff or 4 * d_model\n",
    "        self.attention = attention\n",
    "        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1, bias=False)\n",
    "        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1, bias=False)\n",
    "        self.decomp1 = series_decomp(moving_avg)\n",
    "        self.decomp2 = series_decomp(moving_avg)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.activation = F.relu if activation == \"relu\" else F.gelu\n",
    "\n",
    "    def forward(self, x, attn_mask=None):\n",
    "        new_x, attn = self.attention(\n",
    "            x, x, x,\n",
    "            attn_mask=attn_mask\n",
    "        )\n",
    "        x = x + self.dropout(new_x)\n",
    "        x, _ = self.decomp1(x)\n",
    "        y = x\n",
    "        y = self.dropout(self.activation(self.conv1(y.transpose(-1, 1))))\n",
    "        y = self.dropout(self.conv2(y).transpose(-1, 1))\n",
    "        res, _ = self.decomp2(x + y)\n",
    "        return res, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cde75504",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Autoformer encoder\n",
    "    \"\"\"\n",
    "    def __init__(self, attn_layers, conv_layers=None, norm_layer=None):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.attn_layers = nn.ModuleList(attn_layers)\n",
    "        self.conv_layers = nn.ModuleList(conv_layers) if conv_layers is not None else None\n",
    "        self.norm = norm_layer\n",
    "\n",
    "    def forward(self, x, attn_mask=None):\n",
    "        attns = []\n",
    "        if self.conv_layers is not None:\n",
    "            for attn_layer, conv_layer in zip(self.attn_layers, self.conv_layers):\n",
    "                x, attn = attn_layer(x, attn_mask=attn_mask)\n",
    "                x = conv_layer(x)\n",
    "                attns.append(attn)\n",
    "            x, attn = self.attn_layers[-1](x)\n",
    "            attns.append(attn)\n",
    "        else:\n",
    "            for attn_layer in self.attn_layers:\n",
    "                x, attn = attn_layer(x, attn_mask=attn_mask)\n",
    "                attns.append(attn)\n",
    "\n",
    "        if self.norm is not None:\n",
    "            x = self.norm(x)\n",
    "\n",
    "        return x, attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "228429ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class moving_avg(nn.Module):\n",
    "    \"\"\"\n",
    "    Moving average block to highlight the trend of time series\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_size, stride):\n",
    "        super(moving_avg, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.avg = nn.AvgPool1d(kernel_size=kernel_size, stride=stride, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # padding on the both ends of time series\n",
    "        front = x[:, 0:1, :].repeat(1, (self.kernel_size - 1) // 2, 1)\n",
    "        end = x[:, -1:, :].repeat(1, (self.kernel_size - 1) // 2, 1)\n",
    "        x = torch.cat([front, x, end], dim=1)\n",
    "        x = self.avg(x.permute(0, 2, 1))\n",
    "        x = x.permute(0, 2, 1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7bcc28f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class series_decomp(nn.Module):\n",
    "    \"\"\"\n",
    "    Series decomposition block\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_size):\n",
    "        super(series_decomp, self).__init__()\n",
    "        self.moving_avg = moving_avg(kernel_size, stride=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        moving_mean = self.moving_avg(x)\n",
    "        res = x - moving_mean\n",
    "        return res, moving_mean"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "589b17b5",
   "metadata": {},
   "source": [
    "## Autoformer Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f33a56fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Autoformer decoder layer with the progressive decomposition architecture\n",
    "    \"\"\"\n",
    "    def __init__(self, self_attention, cross_attention, d_model, c_out, d_ff=None,\n",
    "                 moving_avg=25, dropout=0.1, activation=\"relu\"):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        d_ff = d_ff or 4 * d_model\n",
    "        self.self_attention = self_attention\n",
    "        self.cross_attention = cross_attention\n",
    "        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1, bias=False)\n",
    "        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1, bias=False)\n",
    "        self.decomp1 = series_decomp(moving_avg)\n",
    "        self.decomp2 = series_decomp(moving_avg)\n",
    "        self.decomp3 = series_decomp(moving_avg)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.projection = nn.Conv1d(in_channels=d_model, out_channels=c_out, kernel_size=3, stride=1, padding=1,\n",
    "                                    padding_mode='circular', bias=False)\n",
    "        self.activation = F.relu if activation == \"relu\" else F.gelu\n",
    "\n",
    "    def forward(self, x, cross, x_mask=None, cross_mask=None):\n",
    "        x = x + self.dropout(self.self_attention(\n",
    "            x, x, x,\n",
    "            attn_mask=x_mask\n",
    "        )[0])\n",
    "        x, trend1 = self.decomp1(x)\n",
    "        x = x + self.dropout(self.cross_attention(\n",
    "            x, cross, cross,\n",
    "            attn_mask=cross_mask\n",
    "        )[0])\n",
    "        x, trend2 = self.decomp2(x)\n",
    "        y = x\n",
    "        y = self.dropout(self.activation(self.conv1(y.transpose(-1, 1))))\n",
    "        y = self.dropout(self.conv2(y).transpose(-1, 1))\n",
    "        x, trend3 = self.decomp3(x + y)\n",
    "\n",
    "        residual_trend = trend1 + trend2 + trend3\n",
    "        residual_trend = self.projection(residual_trend.permute(0, 2, 1)).transpose(1, 2)\n",
    "        return x, residual_trend\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4aebf019",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Autoformer encoder\n",
    "    \"\"\"\n",
    "    def __init__(self, layers, norm_layer=None, projection=None):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        self.norm = norm_layer\n",
    "        self.projection = projection\n",
    "\n",
    "    def forward(self, x, cross, x_mask=None, cross_mask=None, trend=None):\n",
    "        for layer in self.layers:\n",
    "            x, residual_trend = layer(x, cross, x_mask=x_mask, cross_mask=cross_mask)\n",
    "            trend = trend + residual_trend\n",
    "\n",
    "        if self.norm is not None:\n",
    "            x = self.norm(x)\n",
    "\n",
    "        if self.projection is not None:\n",
    "            x = self.projection(x)\n",
    "        return x, trend"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6cd5b798",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4435e4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.seq_len = CFG['TRAIN_WINDOW_SIZE'] + CFG['PREDICT_SIZE'] # 전체 사용할 데이터 사이즈\n",
    "        self.label_len = CFG['TRAIN_WINDOW_SIZE']\n",
    "        self.pred_len = CFG['PREDICT_SIZE']\n",
    "        self.output_attention = CFG['output_attention']\n",
    "\n",
    "        #Decomp\n",
    "        kernel_size = 25 #이동평균 일단 5일로설정\n",
    "        self.decomp = series_decomp(kernel_size)\n",
    "\n",
    "        # Embedding\n",
    "        # The series-wise connection inherently contains the sequential information.\n",
    "        # Thus, we can discard the position embedding of transformers.\n",
    "        self.enc_embedding = DataEmbedding_wo_pos(CFG['enc_in'], CFG['d_model'], 5, 11, CFG['embed'], CFG['freq'], CFG['drop_out'])\n",
    "\n",
    "\n",
    "\n",
    "        self.dec_embedding = DataEmbedding_wo_pos(CFG['enc_in'], CFG['d_model'], 5, 11, CFG['embed'], CFG['freq'], CFG['drop_out'])\n",
    "\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = Encoder(\n",
    "            [\n",
    "                EncoderLayer(\n",
    "                    AutoCorrelationLayer(\n",
    "                        AutoCorrelation(False, CFG['factor'], attention_dropout=CFG['drop_out'],\n",
    "                                        output_attention=CFG['output_attention']),\n",
    "                        CFG['d_model'], CFG['n_heads']),\n",
    "                    CFG['d_model'],\n",
    "                    CFG['d_ff'],\n",
    "                    moving_avg=25,\n",
    "                    dropout=0.1,\n",
    "                    activation='gelu'\n",
    "                ) for l in range(CFG['e_layers'])\n",
    "            ],\n",
    "            norm_layer=my_Layernorm(CFG['d_model'])\n",
    "        )\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder = Decoder(\n",
    "            [\n",
    "                DecoderLayer(\n",
    "                    AutoCorrelationLayer(\n",
    "                        AutoCorrelation(True, CFG['factor'], attention_dropout=CFG['drop_out'],\n",
    "                                        output_attention=False),\n",
    "                        CFG['d_model'], CFG['n_heads']),\n",
    "                    AutoCorrelationLayer(\n",
    "                        AutoCorrelation(False, CFG['factor'], attention_dropout=CFG['drop_out'],\n",
    "                                        output_attention=False),\n",
    "                        CFG['d_model'], CFG['n_heads']),\n",
    "                    CFG['d_model'],\n",
    "                    CFG['c_out'],\n",
    "                    CFG['d_ff'],\n",
    "                    moving_avg=25,\n",
    "                    dropout=0.1,\n",
    "                    activation='gelu'\n",
    "                )\n",
    "                for l in range(CFG['d_layers'])\n",
    "            ],\n",
    "            norm_layer=my_Layernorm(CFG['d_model']),\n",
    "            projection=nn.Linear(CFG['d_model'], CFG['c_out'], bias=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, product_data, x_enc, x_mark_enc, x_dec, x_mark_dec,\n",
    "            enc_self_mask=None, dec_self_mask=None, dec_enc_mask=None):\n",
    "\n",
    "            # decomp init\n",
    "            mean = torch.mean(x_enc, dim=1).unsqueeze(1).repeat(1, self.pred_len, 1)\n",
    "            zeros = torch.zeros([x_dec.shape[0], self.pred_len, 1], device=x_enc.device)\n",
    "            \n",
    "            seasonal_init, trend_init = self.decomp(x_enc)  # 판매량만 사용해서 구함\n",
    "            # decoder input\n",
    "            trend_init = torch.cat([trend_init[:, -self.label_len:, :], mean], dim=1)\n",
    "            seasonal_init = torch.cat([seasonal_init[:, -self.label_len:, :], zeros], dim=1)\n",
    "            # enc\n",
    "            enc_out = self.enc_embedding(product_data, x_enc, x_mark_enc)  # 제품 정보 추가\n",
    "            enc_out, attns = self.encoder(enc_out, attn_mask=enc_self_mask)\n",
    "\n",
    "            # dec\n",
    "            dec_product_data = product_data[:, -1, :].unsqueeze(1).repeat(1, self.seq_len, 1)\n",
    "\n",
    "            dec_out = self.dec_embedding(dec_product_data, seasonal_init, x_mark_dec)\n",
    "            seasonal_part, trend_part = self.decoder(dec_out, enc_out, x_mask=dec_self_mask, cross_mask=dec_enc_mask,\n",
    "                                                    trend=trend_init)\n",
    "            # final\n",
    "            dec_out = trend_part + seasonal_part\n",
    "\n",
    "            if self.output_attention:\n",
    "                return dec_out[:, -self.pred_len:, :], attns\n",
    "            else:\n",
    "                return dec_out[:, -self.pred_len:, :]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c83fa73-30d5-489c-852b-d655f76a200c",
   "metadata": {},
   "source": [
    "## Run !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "73c74950",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_loader, val_loader, device, model_scheduler, scale_max_dict, scale_min_dict):\n",
    "    model.to(device)\n",
    "    criterion = nn.MSELoss().to(device)\n",
    "    best_loss = 9999999\n",
    "    best_model = None\n",
    "    \n",
    "    for epoch in range(1, CFG['EPOCHS']+1):\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        \n",
    "        for product_data, batch_x, batch_y, batch_x_mark, batch_y_mark in tqdm(iter(train_loader)):\n",
    "            product_data = product_data.to(device)\n",
    "            batch_x = batch_x.to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "            batch_x_mark = batch_x_mark.to(device)\n",
    "            batch_y_mark = batch_y_mark.to(device)\n",
    "            \n",
    "            # decoder input\n",
    "            dec_inp = torch.cat([batch_x, torch.zeros_like(batch_y).unsqueeze(-1)], dim=1).to(device)\n",
    "\n",
    "            # decoder time info\n",
    "            dec_mark_inp = torch.cat([batch_x_mark, batch_y_mark], dim=1).to(device)\n",
    "\n",
    "            output = model(product_data, batch_x, batch_x_mark, dec_inp, dec_mark_inp)[0]\n",
    "            output = output.squeeze(-1)\n",
    "\n",
    "            batch_y = batch_y[:, -CFG['PREDICT_SIZE']:].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(output, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss.append(loss.item())\n",
    "        \n",
    "        val_loss = validation(model, val_loader, criterion, device, scale_max_dict, scale_min_dict)\n",
    "        print(f'Epoch : [{epoch}] Train Loss : [{np.mean(train_loss):.5f}] Val Loss : [{val_loss:.5f}]')\n",
    "        \n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_model = model\n",
    "            print('Model Saved')\n",
    "            \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "996c6270",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, val_loader, criterion, device, scale_max_dict, scale_min_dict):\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for product_data, batch_x, batch_y, batch_x_mark, batch_y_mark in tqdm(iter(train_loader)):\n",
    "            product_data = product_data.to(device)\n",
    "            batch_x = batch_x.to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "            batch_x_mark = batch_x_mark.to(device)\n",
    "            batch_y_mark = batch_y_mark.to(device)\n",
    "            \n",
    "            # decoder input\n",
    "            dec_inp = torch.cat([batch_x, torch.zeros_like(batch_y).unsqueeze(-1)], dim=1).to(device)\n",
    "\n",
    "            # decoder time info\n",
    "            dec_mark_inp = torch.cat([batch_x_mark, batch_y_mark], dim=1).to(device)\n",
    "\n",
    "            output = model(product_data, batch_x, batch_x_mark, dec_inp, dec_mark_inp)[0]\n",
    "            output = output.squeeze(-1)\n",
    "            \n",
    "            batch_y = batch_y[:, -CFG['PREDICT_SIZE']:].to(device)\n",
    "            \n",
    "            loss = criterion(output, batch_y)\n",
    "            val_loss.append(loss.item())\n",
    "\n",
    "    return np.mean(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a1570b00-a309-4e5e-b53d-5848ba53eb19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:00<00:03,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:01<00:02,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:01<00:01,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [00:02<00:01,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [00:03<00:00,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([232, 90, 1])\n",
      "torch.Size([232, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.77it/s]\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:00<00:02,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:00<00:01,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:01<00:01,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [00:02<00:01,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [00:02<00:00,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([232, 90, 1])\n",
      "torch.Size([232, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:02<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [1] Train Loss : [0.47038] Val Loss : [0.44020]\n",
      "Model Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:00<00:03,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:01<00:02,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:01<00:01,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [00:02<00:01,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [00:03<00:00,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([232, 90, 1])\n",
      "torch.Size([232, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.78it/s]\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:00<00:02,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:01<00:02,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:01<00:01,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [00:02<00:01,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [00:02<00:00,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([232, 90, 1])\n",
      "torch.Size([232, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:02<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [2] Train Loss : [0.25665] Val Loss : [0.07507]\n",
      "Model Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:00<00:03,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:01<00:02,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:01<00:01,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [00:02<00:01,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [00:03<00:00,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([232, 90, 1])\n",
      "torch.Size([232, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.79it/s]\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:00<00:03,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:01<00:02,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:01<00:01,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [00:02<00:01,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [00:02<00:00,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([232, 90, 1])\n",
      "torch.Size([232, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:02<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [3] Train Loss : [0.15975] Val Loss : [0.07792]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:00<00:03,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:01<00:02,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:01<00:01,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [00:02<00:01,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [00:03<00:00,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([232, 90, 1])\n",
      "torch.Size([232, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.78it/s]\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:00<00:02,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:00<00:01,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:01<00:01,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [00:01<00:00,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [00:02<00:00,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([232, 90, 1])\n",
      "torch.Size([232, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:02<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [4] Train Loss : [0.11720] Val Loss : [0.05907]\n",
      "Model Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:00<00:03,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:01<00:02,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:01<00:01,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [00:02<00:01,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [00:03<00:00,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([232, 90, 1])\n",
      "torch.Size([232, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.78it/s]\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:00<00:02,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:00<00:01,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:01<00:01,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [00:01<00:00,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [00:02<00:00,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([232, 90, 1])\n",
      "torch.Size([232, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:02<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [5] Train Loss : [0.09783] Val Loss : [0.04981]\n",
      "Model Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:00<00:03,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:01<00:02,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:01<00:01,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [00:02<00:01,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [00:03<00:00,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([232, 90, 1])\n",
      "torch.Size([232, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.77it/s]\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:00<00:02,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:00<00:01,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:01<00:01,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [00:01<00:00,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [00:02<00:00,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([232, 90, 1])\n",
      "torch.Size([232, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:02<00:00,  2.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [6] Train Loss : [0.08702] Val Loss : [0.04325]\n",
      "Model Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:00<00:03,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:01<00:02,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:01<00:01,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [00:02<00:01,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [00:03<00:00,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([232, 90, 1])\n",
      "torch.Size([232, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.78it/s]\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:00<00:02,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:00<00:01,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:01<00:01,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [00:01<00:00,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [00:02<00:00,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([232, 90, 1])\n",
      "torch.Size([232, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:02<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [7] Train Loss : [0.07934] Val Loss : [0.03868]\n",
      "Model Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:00<00:03,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:01<00:02,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:01<00:01,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [00:02<00:01,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [00:03<00:00,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([232, 90, 1])\n",
      "torch.Size([232, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.77it/s]\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:00<00:02,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:00<00:01,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:01<00:01,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [00:02<00:01,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [00:02<00:00,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([232, 90, 1])\n",
      "torch.Size([232, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:02<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [8] Train Loss : [0.07742] Val Loss : [0.03374]\n",
      "Model Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:00<00:03,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:01<00:02,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:01<00:01,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [00:02<00:01,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [00:03<00:00,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([232, 90, 1])\n",
      "torch.Size([232, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.77it/s]\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:00<00:02,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:00<00:01,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:01<00:01,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [00:01<00:00,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [00:02<00:00,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([232, 90, 1])\n",
      "torch.Size([232, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:02<00:00,  2.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [9] Train Loss : [0.07515] Val Loss : [0.03481]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:00<00:03,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:01<00:02,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:01<00:01,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [00:02<00:01,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [00:03<00:00,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([232, 90, 1])\n",
      "torch.Size([232, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.78it/s]\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:00<00:02,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:00<00:01,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:01<00:01,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [00:01<00:00,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 90, 1])\n",
      "torch.Size([512, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [00:02<00:00,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([232, 90, 1])\n",
      "torch.Size([232, 111, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:02<00:00,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [10] Train Loss : [0.07262] Val Loss : [0.03448]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "\n",
    "model_scheduler = []\n",
    "optimizer = torch.optim.AdamW(params = model.parameters(), lr = CFG[\"LEARNING_RATE\"])\n",
    "infer_model = train(model, optimizer, train_loader, val_loader, device, model_scheduler,scale_max_dict,scale_min_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b20af7-f5b1-4a7a-8eb9-7dde5bbf3d04",
   "metadata": {},
   "source": [
    "## 모델 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b01d7ca0-899e-4515-a43e-890549f8f3c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_input' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/ksw2/hdd2/대회/Aimers_Autoformer/Autoformer.ipynb 셀 44\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B210.102.181.225/home/ksw2/hdd2/%EB%8C%80%ED%9A%8C/Aimers_Autoformer/Autoformer.ipynb#X61sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m test_dataset \u001b[39m=\u001b[39m CustomDataset(test_input, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B210.102.181.225/home/ksw2/hdd2/%EB%8C%80%ED%9A%8C/Aimers_Autoformer/Autoformer.ipynb#X61sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m test_loader \u001b[39m=\u001b[39m DataLoader(test_dataset, batch_size \u001b[39m=\u001b[39m CFG[\u001b[39m'\u001b[39m\u001b[39mBATCH_SIZE\u001b[39m\u001b[39m'\u001b[39m], shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, num_workers\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_input' is not defined"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. 셀의 코드를 검토하여 오류의 가능한 원인을 식별하세요. 자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'> 여기 </a> 를 클릭하세요. 자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "test_dataset = CustomDataset(test_input, None)\n",
    "test_loader = DataLoader(test_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86aa1df7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214f30d4-2b19-479f-89b7-bf5bb2adc111",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m커널이 종료되었습니다. 오류: /home/ksw2/anaconda3/envs/eunseo/bin/python: No module named ipykernel_launcher... 자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "def inference(model, test_loader, device):\n",
    "    predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X in tqdm(iter(test_loader)):\n",
    "            X = X.to(device)\n",
    "            \n",
    "            output = model(X)\n",
    "            \n",
    "            # 모델 출력인 output을 CPU로 이동하고 numpy 배열로 변환\n",
    "            output = output.cpu().numpy()\n",
    "            \n",
    "            predictions.extend(output)\n",
    "    \n",
    "    return np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b76e053-6fd2-44a7-8631-d903e7ffa292",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m커널이 종료되었습니다. 오류: /home/ksw2/anaconda3/envs/eunseo/bin/python: No module named ipykernel_launcher... 자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "pred = inference(infer_model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517978aa-445a-4ece-9217-432682f71230",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m커널이 종료되었습니다. 오류: /home/ksw2/anaconda3/envs/eunseo/bin/python: No module named ipykernel_launcher... 자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "# 추론 결과를 inverse scaling\n",
    "for idx in range(len(pred)):\n",
    "    pred[idx, :] = pred[idx, :] * (scale_max_dict[idx] - scale_min_dict[idx]) + scale_min_dict[idx]\n",
    "    \n",
    "# 결과 후처리\n",
    "pred = np.round(pred, 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90fa77e-fd03-4539-98fe-563fe2a25121",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m커널이 종료되었습니다. 오류: /home/ksw2/anaconda3/envs/eunseo/bin/python: No module named ipykernel_launcher... 자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48b50eb-d2d8-4c2d-a5e7-9607220fd794",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78c84bb-5dbe-4fb3-aff0-7e229ae29a8d",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m커널이 종료되었습니다. 오류: /home/ksw2/anaconda3/envs/eunseo/bin/python: No module named ipykernel_launcher... 자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "submit = pd.read_csv('./sample_submission.csv')\n",
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db62d9c-b3ad-440a-8cc7-4897b2e4860f",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m커널이 종료되었습니다. 오류: /home/ksw2/anaconda3/envs/eunseo/bin/python: No module named ipykernel_launcher... 자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "submit.iloc[:,1:] = pred\n",
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4142f749-f20f-4797-b586-581e5c778297",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m커널이 종료되었습니다. 오류: /home/ksw2/anaconda3/envs/eunseo/bin/python: No module named ipykernel_launcher... 자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "submit.to_csv('./baseline_submit.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "team2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
